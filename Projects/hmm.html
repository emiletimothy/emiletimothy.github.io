<!DOCTYPE html>
<html lang="en">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<body class="w3-light-grey">
<title>Emile Timothy</title>
<link rel="stylesheet" href="../CSS/prime_stylesheet.css">
<link rel="stylesheet" type="text/css" href="../style.css">  
    <link rel="stylesheet" href="../CSS/oswald.css">
    <link rel="stylesheet" href="../CSS/opensans.css">
    <link rel="stylesheet" href="../CSS/awesomemin.css">
</head> 
  <style>
    h1,h2,h3,h4,h5,h6 {font-family: "Oswald"}
    body {font-family: "Open Sans"}
    html {
      scroll-behavior: smooth;
    }

/* Style the button that is used to open and close the collapsible content */
.collapsible {
  background-color: #000000;
  color: #ffffff;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  outline: 10px white;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
}

.collapsible:after {
  background-color: #000000;
  content: '+'; /* Unicode character for "plus" sign (+) */
  font-size: 13px;
  outline: #000000;
  color: #ffffff;
  float: right;
  margin-left: 5px;
}

.b1-active:after {
  color: #ffffff;
  font-size:10px;
  content: "-"; /* Unicode character for "minus" sign (-) */
}

/* Add a background color to the button if it is clicked on (add the .active class with JS), and when you move the mouse over it (hover) */
.b1-active, .collapsible:hover {
  background-color: #000000;
}

.content {
  padding: 0 18px;
  color: white;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
}

    </style>

<div class="background_image">
<div class="header">
    <div>
        <div style="float: left"><a href="../index.html"><img src="Pictures/icons/logo_background_nobackground.png", alt="Main Page", style="width:100px;height:100px";></a></div>
        <div>
            <div id="hed1"><br><h2>Projects</h2></div>
            <div id="hed2"><a href="../index.html"><div class="x"><img src="Pictures/icons/x-mark.png", style="width:30px;height:30px;float:right";><img src="Pictures/icons/x-mark-2.png", class="img-top", style="width:30px;height:30px;float:right";></a></div></div>
        </div>
    </div>
</div>
</div>

<div class="navbar">
  <a href="../index.html">Home</a>
  <a href="../about-me.html">About Me</a>
  <a href="../projects.html" class="active">Projects</a>
  <a href="../blog.html">Blog</a>
  <a href="../talks.html">Talks</a>
  <a href="../outreach.html">Outreach</a>
  <a href="../gallery.html">Gallery</a>
  <a href="../CV.html">CV</a>
  <a href="../contact.html">Contact</a>
</div>

<style>
.centertitleph11 {
  display: block;
  margin-left: auto;
  margin-right: auto;
  text-align: center;
}

.container {
  position: relative;
}


.text {
  background-color: white;
  color: black;
  font-size: 3vw; /* Responsive font size */
  font-weight: bold;
  margin: 0 auto; /* Center the text container */
  padding: 10px;
  width: 70.5%;
  text-align: center; /* Center text */
  position: absolute; /* Position text */
  top: 25%; /* Position text in the middle */
  left: 50%; /* Position text in the middle */
  transform: translate(-50%, -50%); /* Position text in the middle */
  mix-blend-mode: screen; /* This makes the cutout text possible */
  font-family: "Oswald", sans-serif;
  text-shadow: 3px 3px 3px #ababab;
}

/* Style the button that is used to open and close the collapsible content */
.collapsible {
  background-color: #000000;
  color: #ffffff;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  outline: 10px white;
  border: none;
  text-align: center;
  outline: none;
  font-size: 15px;
}

.collapsible:after {
  background-color: #000000;
  content: '+'; /* Unicode character for "plus" sign (+) */
  font-size: 13px;
  outline: #000000;
  color: #ffffff;
  float: right;
  margin-left: 5px;
}

.b1-active:after {
  color: #ffffff;
  font-size:10px;
  content: "-"; /* Unicode character for "minus" sign (-) */
}

/* Add a background color to the button if it is clicked on (add the .active class with JS), and when you move the mouse over it (hover) */
.b1-active, .collapsible:hover {
  background-color: #000000;
}

.content {
  padding: 0 18px;
  color: black;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.2s ease-out;
}


/* Bottom right text */
.text-block {
  position: absolute;
  bottom: 20px;
  right: 20px;
  background-color: black;
  color: white;
  padding-left: 20px;
  padding-right: 20px;
}

.image-container {
  background-image: url("ProjectPictures/hmm.jpeg"); /* The image used - important! */
  background-size: cover;
  position: relative; /* Needed to position the cutout text in the middle of the image */
  height: 70%; /* Some height */
}
</style>

<div class="image-container">
  <div class="text">Hidden Markov Models to Generate Shakespearean Sonnets</div>
</div>



<div class="w3-row w3-padding">
  <div class="w3-col l7 s12" style="float:none !important; margin:auto; position:relative; z-index:10; margin-top:-10%;">
    <div class="w3-container w3-white w3-margin w3-padding-large">
      <div class="w3">

<p>During the winter quarter of my sophomore year at Caltech, I took CS 155 which is a graduate class on Machine Learning and Data Mining, taught by Professor <a href="http://www.yisongyue.com/">Yisong Yue</a>. One of our last week-long assignments was to individually create a Hidden Markov Model (HMM) using the Viterbi, backpropagation, and feedforward algorithms. Following this, I formed a group with my friends (Andrew, Basel, and Julen), and we used the HMM's we had individually constructed to find the transition and emission matrices of Shakespearean words from a corpus of texts using the CMU Pronouncing Dictionary. We then used the Baum-Welch algorithm, to generate somewhat meaningful Shakespearean sonnets while preserving the stress-unstress syllable pattern invariant. Here, I have showcased some of the sonnets generated by our algorithm, explained (to some technical details) the underlying algorithms involved in these tasks, and embedded the final reports that we presented to the class.<br><br></p></div>


<button class="collapsible centertitleph11"><p5><strong>Showcase: Synthetic Shakespearean Sonnet</strong></p5></button>
  <div class="content">


<br><h5 style="text-align:center;"><u>Sonnet 1</u></h5>

<p style="text-align:center;"><code>

Rather of the touches since torment<br>
Memorial which ride some freezings course<br>
Dost why that not me orient<br>
He writ on my to perforce<br><br>

Have now alone make the fine<br>
Policy follow he they his rude<br>
Verse and so sight thy line<br>
Flatter now out short his food<br><br>

By being you rain our beyond<br>
What dost fair deserving and nights<br>
Ransom on thy offenders being bond<br>
Of the might for sweet light's<br><br>

Do woman's by your excuse towards<br>
Though whom plain should this affords<br></code>


<br><h5 style="text-align:center;"><u>Sonnet 2</u></h5>

<p style="text-align:center;"><code>
Can unto him and mortal gathered hold <br>
Remembered ransom and for do asleep <br>
That ills the how to not did I be fold <br>
The stewards and that stronger are for steep <br><br>

Is of consumed with other not in shine <br>
And poet's you with which to to and pride <br>
In any with to doth and my will nine <br>
For hours is to with the rebel eyed <br><br>

In how in answer smother flatter where <br>
The kind be painting so a master fault <br>
Is is his what and motion as with bear <br>
It I be my a all will to to halt <br><br>


The lusty eyes familiar my the vowed <br>
That a are my a thou to I will loud <br>

</code>


<br><h5 style="text-align:center;"><u>Sonnet 3</u></h5>
<p style="text-align:center;"><code>

Still doth both painted cheek present<br>
Spite my how some bring predict<br>
Glad the it now beseechers pleasant<br>
Earth such o'ercharged cries and pricked<br><br>

Charge or praise ensconce gluttoning attending<br>
I new thou see thy another's<br>
Enmity in she and thee bending<br>
And and that the untrimmed others'<br><br>

In against eye of savour smoke<br>
Your the now and that twice<br>
Hath she although sometime shamefully broke<br>
Thou be at form night devise<br><br>

For hours affairs of to told<br>
Is thy you fiery of fold<br>
</code>


<br><h5 style="text-align:center;"><u>Sonnet 4</u></h5>
<p style="text-align:center;"><code>

Thou art to great with gentle work did frame <br>
The lovely gaze where every eye doth dwell <br>
Will play the tyrants to the very same,<br>
And that unfair which fairly doth excel:<br><br>
For never-resting time leads summer on<br>
To hideous winter and confounds him there,<br>
Sap checked with frost and lusty leaves quite gone,<br>
Beauty o’er-snowed and bareness every where:<br><br>
Then were not summer’s distillation left<br>
A liquid prisoner pent in walls of glass,<br>
Beauty’s effect with beauty were bereft,<br>
Nor it nor no remembrance what it was.<br><br>
But flowers distilled though they with winter meet,<br>
Leese but their show, their substance still lives sweet.<br></code>
</p>



<br><h5 style="text-align:center;"><u>Sonnet 5</u></h5>
<p style="text-align:center;"><code>

I three not as sweet as your alone seeing.<br>
Death's upon comfort of thy sort acquainted<br>
Not never o for mark three is told 'greeing<br>
Let so all this world seem amen attainted<br><br>

Be hours and upon nor again keen <br>
She never what i would you luck to thee<br>
Said i when thou an accident unseen<br>
Who thing felt you thy sweet been down his me<br><br>
How himself i seek yea rank the cloud praise<br>
Up me in strange short a of the back fair<br>
Cloud the be soul doth keep too old time's days<br>
On where created you upon me self air<br><br>

To be give the argument to foiled gems<br>
So edge me secret wilt cannot strange hems<br></code>


<br><h5 style="text-align:center;"><u>Sonnet 6</u></h5>
<p style="text-align:center;"><code>let deep could youth is it <br>
heaven's translate of is you doth <br>
exchanged those prime but kind among <br>
and i it set seems make<br>
men looks canst that so hugely <br>
not forgot my least all time's <br>
hate' lead thee your heart i<br>
which i needs beguiled make crystal<br>
a what jacks the than make<br>
seen my fair knows me what<br>
thee pebbled you distempered deceived sweet<br>
hell see love of hours me<br>
for brought let that eclipse dear<br>
thee so all all so then<br>
</code></p>

</div>

<br>

<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

<button class="collapsible centertitleph11">Building a Hidden Markov Model</button>
  <div class="content"><br>
Consider the following set-up. It's actually the simplest Hidden Markov Model. It initializes itself to one state (or one vertex), and then stays at itself with probability \(P(A|A)\) or \(P(B|B)\) and transitions to the other vertex with probability \(P(A|B)\) or \(P(B|A)\). In this model, vertex A represents the uniform distribution from \(\{1,...,6\}\), and vertex B represents the uniform distribution from \(\{1,...,4\}\). So, we write that the initial distribution is \(\pi = (\pi_A, \pi_B)\). In real-world applications, the vertices of the Hidden Markov Model are categories that describe how the output of the model evolves over iterations.<br><br>

<img src="ProjectPictures/easyHMM.png" style="width:100%">
The question that the Hidden Markov Model answers is that if you're given an observed sequence upon sampling from this Markov distribution, say \(1,4,3,6,6,4\), can you predict the most likely sequence and what is the probability of this sequence occurring? Finally, for any element in the distribution that could have belonged to either \(A\) or \(B\), for instance any number from \(\{1,2,3,4\}\), what is the probability that the element belonged to \(A\) (and by contrast, \(B\))?<br><br>

These questions are actually well-answered by the Hidden Markov Model algorithms. The most likely sequence, given some observations, is predicted by the <i>Viterbi algorithm</i>, and its corresponding likelihood is determined by the <i>Forward algorithm</i>. Finally, the probability that an element from an observation belonged to a specific 'vertex' can be determined by the <i>Backward algorithm</i>. To explain these solutions (the forward, backward and Viterbi algorithms) better, we develop some essential notation.

$$\alpha^t(i) = \mathbb{P}(\text{observed sequence, ending in state i at w/t})$$
$$\beta^t(i) = \mathbb{P}(\text{observation after t | ending in state i at w/t})$$
$$\delta^t(i) = \max\limits_{\text{observations}}(\mathbb{P}(\text{observation ending in state i at w/t}))$$
Before I continue, there is one natural question to ask: this 2-vertex Hidden Markov Model is pretty cool, but obviously it doesn't capture the complexity of large datasets. So, maybe consider the \(m\)-vertex Hidden Markov Model. Is there even a unique or existing solution for the most likely forecasted sequence given some  predictions? Turns out that the answer to this question is yes! The Hammersley-Clifford Theorem (or the fundamental theorem of random fields) states that the directed graphical model \(V_\Delta(M_D)\) is equal to the image of the parameter space \(\theta\) under the map \(F_D\). Specifically, it states that a probability distribution has a strictly positive mass if and only if it it is a Gibbs random field: its probability density must be factorizable over the cliques (or complete subgraphs) of the graph. The implication of this result is that for all m and for any observed sequence, the \(m\)-vertex Hidden Markov Model has a unique solution for a predicted future sequence, which can be approximated by common algorithmic tools with neat twists.<br><br>

So, first things first, how do we convert knowledge of our observations to knowledge about the hidden variables behind their system? Can we find out which vertex each of these elements came from? Yes again, and that's exactly what the Viterbi algorithm does.
<img src="ProjectPictures/hmmv1.png" style="width:100%"><br>

<img src="ProjectPictures/hmmv2.png" style="width:100%">

<br>

<br><h5 style="text-align:center;"><u>Implementing the Viterbi Algorithm</u></h5>
The Viterbi algorithm first uses the observations to find the path of maximum probability, which is characterized by:
$$ \text{Path} = \theta'_{\sigma_1 \tau_1}\theta_{\sigma_1 \sigma_2} \theta'_{\sigma_2 \tau_2} \theta_{\sigma_2 \sigma_3} \theta'_{\sigma_3 \tau_3} \theta_{\sigma_3 \sigma_4} \theta'_{\sigma_4 \tau_4}$$

<img src="ProjectPictures/viterbimain.png" style="width:100%"><br><br>

Essentially, the Viterbi algorithm seeks to find the \(\arg\max\limits_y P(y|x)\). We can actually write an explicit formula for this value.<br>
$$\begin{aligned}
  \arg\max\limits_y P(y|x) &= \arg\max\limits_y \frac{P(y,x)}{P(x)}\\
  &= \arg\max\limits_y P(y,x) \\
  &= \arg\max\limits_y \log P(x|y) + \log P(y)
\end{aligned}
$$
So, for \(k=1,...,M\), we can use Dynamic Programming to iteratively solve for each \(\log(\hat{Y}^k(Z))\), where Z loops over every possible probability of state, to produce the best \(\hat{Y}^M(Z)\), which is also known as the Mean A Posteriori (MAP) inference. So, the Viterbi algorithm models the pairwise transitions between states. The reason it works is completely justified by the Bayesian principle. For instance, consider a 1st order HMM, characterized by the joint probability distribution
$$
\begin{aligned}
P(x,y) &= P(\text{End}|y^M) \prod\limits_{i=1}^M P(y^i | y^{i-1}) \prod\limits_{i=1}^M P(x^i | y^i) \\
P(x|y) &= \prod\limits_{i=1}^M P(x^i | y^i)
\end{aligned}
$$
Since we know that \(P(y) = P(\text{End}|y^M)\prod\limits_{i=1}^M P(y^i | y^{i-1})\), we can use this characterization to recover the original Bayes' formula, which states that:
$$ P(x|y) = \frac{P(x,y)}{P(y)} $$

So, what is the actual algorithm? Given an input of the observation space \(O = \{o_1, ..., o_N\} \subseteq S\), a state space \(S = \{s_1, ..., s_K\}\), an array of initial possibilities \(\Pi = (\pi_1,...\pi_K)\) such that \(x_1 = s_i\), a sequence of observations \(Y = (y_1, ..., y_T)\) such that \(y_t = o_i\) if the observation at time \(t\) is \(o_i\), a transition matrix \(A\) of size \(K\times K\) such that \(A_{ij}\) stores the transition probability of transiting from state \(s_i\) to state \(s_j\), and an emission matrix \(B\) of size \(K\times N\) such that \(B_{ij}\) stores the probability of observing \(o_j\) from state \(s_i\), the Viterbi algorithm outputs the most likely hidden state sequence \(X = (x_1, ..., x_T)\). Below is the pseudocode from Wikipedia for the general HMM solution, and I've embedded my code for the Viterbi algorithm to generate Shakespearean sonnets in the later sections below.<br>


<img src="ProjectPictures/Viterbi.png" style="width:100%;"></p>

<br><h5 style="text-align:center;"><u>Implementing the Viterbi Forward and Backward Algorithm</u></h5><br>


Here are some conceptual ideas of what happens in the Forward and Backward algorithms, respectively.<br><br>


<img src="ProjectPictures/Viterbiforward.png" style="width:100%;"></p><br><br>


<img src="ProjectPictures/Viterbibackward.png" style="width:100%;"></p><br>


So, for the forward algorithm, the goal is to solve for every \(\alpha_z(i) = P(x^{1:i},y^i=Z|A,O)\). One naive (exponential time) solution is to let
$$ \alpha_z(i) = P(x^{1:i},y^i=Z|A,O) = \sum\limits_{y^{1:i-1}} P(x^{1:i},y^i=Z,y^{1:i-1}|A,O)$$
A better solution is to use DP and recursively solve for \(\alpha_z(i) \). So,
$$ 
\begin{aligned}
\alpha_z(1) &= P(y^1 = z|y^0) P(x^1 | y^1 = z) = O_{x^1, z} A_{\text{z,start}} \\
\alpha_z(i+1) &= O_{x^{i+1},z} \sum\limits_{j=1}^L \alpha_j(i) A_{z,j}
\end{aligned}
$$

Similarly, for the backward algorithm, the goal is to solve for every \(\beta_z(i) = P(x^{1+i:M}|y^i=Z,A,O)\). The naive (exponential time) solution is to let
$$ \beta_z(i) = P(x^{i+1:M}|y^i=Z|A,O) = \sum\limits_{y^{i+1:L}} P(x^{i+1:M},y^{i+1:M} | y^i = Z, A, O)$$
A better solution is to use DP and recursively solve for \(\beta_z(i) \). So,
$$ 
\begin{aligned}
\beta_z(M) &= 1 \\
\beta_z(i) &= \sum\limits_{j=1}^L \beta_j(i+1) A_{j,z} O_{x^{i+1},j}
\end{aligned}
$$

Here's the code that computes these functions:<br>
<code>    
<pre>  def forward(self, x, normalize=False)
        alphas = [[0. for _ in range(self.L)] for _ in range(len(x) + 1)]
        for state in range(len(self.A_start)):
          alphas[1][state] = self.O[state][x[0]] * self.A_start[state]
        for a, b in enumerate(x[1:]):
          for state in range(self.L):
            for previous_state in range(self.L):
              alphas[a + 2][state] += self.A[previous_state][state] * 
                     self.O[state][b] * alphas[a + 1][previous_state]
          if normalize:
            if (sum(alphas[a + 2]) > 0):
              alphas[a + 2] = [val / sum(alphas[a + 2]) for val in 
                    alphas[a + 2]]
        return alphas<br>
</pre>


<pre>
    def backward(self, x, normalize=False):
        betas = [[0. for _ in range(self.L)] for _ in range(len(x) + 1)]
        betas[M] = [1 for _ in range(self.L)]
        for a, b in reversed(list(enumerate(x))):
          for current_state in range(self.L):
            for transition_state in range(self.L):
              betas[a][current_state] += betas[a + 1][transition_state] * 
              self.A[current_state][transition_state] * 
              self.O[transition_state][b]
          if normalize:
            if (sum(betas[a]) > 0):
              betas[a] = [val / sum(betas[a]) for val in betas[a]]
        return betas
</pre>
</code>

<br>

<h5 style="text-align:center;"><u>Supervised Learning</u></h5>

We can use the supervised learning framework to train the HMM. So, given \(S = \{(x_i,y_i)\}_{i=1}^N\), our goal is to use \(S\) to estimate the maximum likelihood \(P(x,y)\), where
$$P(x,y) = P(\text{End}|y^M)\prod\limits_{i=1}^M P(y^i | y^{i-1}) \prod\limits_{i=1}^M P(x^i | y^i)$$

So, to do this, we define the Transition matrix \(A\) and the Observation matrix \(O\), where

$$ A_{ab} = P(y^{i+1}=a|y^i = b)$$
$$ O_{wz} = P(x^i=w|y^i=z)$$

Using this notation, we have that
$$ \begin{aligned}
P(x,y) &= P(\text{End}|y^M)\prod\limits_{i=1}^M P(y^i|y^{i-1})\prod\limits_{i=1}^M P(x^i|y^i) \\
&= A_{\text{End},y^M}\prod\limits_{i=1}^M A_{y^i,y^{i-1}} \prod\limits_{i=1}^M O_{x^i,y^i}
\end{aligned}
$$

To find the maximum likelihood probability, we have that

$$ \arg\max\limits_{A,O} \prod\limits_{(x,y)\in S} P(x,y) = \arg \max\limits_{A,O} \prod\limits_{(x,y)\in S} P(\text{End}|y^M)\prod\limits_{i=1}^M P(y^i|y^{i-1})\prod\limits_{i=1}^M P(x^i | y^i)$$

We can use supervised learning to estimate each component separately. So,

$$ A_{ab} = \frac{\sum\limits_{j=1}^N \sum\limits_{i=0}^{M_j} \mathbb{1}_{[(y_j^{i+1}=a)\wedge (y_j^i=b)]}}{\sum\limits_{j=1}^N \sum\limits_{i=0}^{M_j}\mathbb{1}_{[y^i_j=b]}}$$

$$ O_{wz} = \frac{\sum\limits_{j=1}^N \sum\limits_{i=1}^{M_j} \mathbb{1}_{[(x_j^{i}=w)\wedge (y_j^i=z)]}}{\sum\limits_{j=1}^N \sum\limits_{i=1}^{M_j}\mathbb{1}_{[y^i_j=z]}}$$

Here's the code that executes the supervised learning framework for the Hidden Markov Model:<br>
<code>
<pre>    def supervised_learning(self, X, Y):
        A = np.zeros((self.L, self.L))
        B = np.zeros((self.L, self.L))
        for state_seq in Y:
          for i in range(len(state_seq) - 1):
            A[state_seq[i]][state_seq[i+1]] += 1
        for i in range(len(A[0])):
          B[:,i] = [probability/sum(A[:,i]) for probability in A[:,i]]
        self.A = B
        O = [[0 for _ in range(self.D)] for _ in range(self.L)]
        for a in range(len(list(X))):
          for state in range(len(list(Y[a]))):
            O[Y[a][state]][X[a][state]] += 1
        for i in range(len(O)):
          self.O[i] = [probability/sum(O[i]) for probability in O[i]]
</pre></code>
There are some glaring assumptions that go along with the supervised learning framework, that are, in most cases, undesirable. For instance, we assume that everything can be decomposed to a pair of products: that \(P(y^{i+1}=a|y^i=b)\) is independent. This is a crucial assumption since it gives us that 
$$P(x,y) = P(\text{End}|y^M)\prod\limits_{i=1}^M P(y^i | y^{i-1}) \prod\limits_{i=1}^M P(x^i | y^i)$$

Another crucial, albeit undesirable, assumption is that we assume that the model can easily learn (to an arbitrarily high precision) the frequentist statistics of how often \(y^{i+1}=a\) when \(y^i=b\) over the training set.

<br><h5 style="text-align:center;"><u>Unsupervised Learning</u></h5>

Due to undesirable assumptions of supervised learning that are mentioned in the previous paragraph, we instead consider the framework of unsupervised learning. Consider the case in which there are no y's. So, \(S = \{x_i\}_{i=1}^N\). Can we still estimate \(P(x,y)\)? Again, the answer is yes! Note that

$$ \arg \max \prod\limits_i P(x_i) = \arg \max \prod\limits_i \sum\limits_y P(x_i, y)$$

So, we now re-define our matrix protagonists \(A\) and \(O\) to:

$$ A_{ab} = P(y^{i+1}=a|y^i = b)$$
$$ O_{wz} = P(x^i=w|y^i=z)$$

We then use the Unsupervised Learning equivalent of the Viterbi algorithm - the Baum-Welch algorithm - to train the Hidden Markov Model. Basically, it initializes \(A\) and \(O\) randomly using the framework above. It then predicts the probabilities of \(y\) for each training \(x\), in what's called the expectation step. In then uses the \(y's\) to estimate the new \(A\) and \(O\) in what's called the maximization step. It then repeats this procedure until the estimates converge onto a value.<br><br>

So, in the expectation step, we are given \(A,O\) and \(x=(x^1,...,x^M)\) and need to predict \(P(y^i)\) for each \(y=(y^1,...,y^M)\), while encoding the current model's beliefs and marginal distribution about \(y\).<br>
<br>

Next, in the maximization step, we seek to find the maximum likelihood over the marginal distribution using a dynamic programming approach:

$$ A_{ab} = \frac{\sum\limits_{j=1}^N \sum\limits_{i=0}^{M_j} P(y_j^i=b, y_j^{i+1}=a)}{\sum\limits_{j=1}^N \sum\limits_{i=0}^{M_j} P(y^i_j=b)}$$

$$ O_{wz} = \frac{\sum\limits_{j=1}^N \sum\limits_{i=1}^{M_j} \mathbb{1}_{[x_j^{i}=w]} P(y_j^i=z)}{\sum\limits_{j=1}^N \sum\limits_{i=1}^{M_j} P(y^i_j=z)}$$

To explain the underlying algorithm further, we introduce some notation. Let \(\alpha_z(i)\) be the probability of observing prefix \(x^{1:i}\) and having the i-th state be \(y^i=z\), and let \(\beta_z(i)\) be the probability of observing suffix \(x^{1+i:m}\) given the i-th state being \(y^i = z\), where

$$ \alpha_z(i) = P(x^{1:i},y^i=Z|A,O)$$
$$ \beta_z(i) = P(x^{1+i:M}|y^i=Z,A,O)$$

So, to compute the marginals, we can combine these two terms to get:

$$P(y^i = z | x) = \frac{\alpha_z(i) \beta_z(i)}{\sum\limits_{z'} a_{z'}(i)\beta_{z'}(i)}$$
$$P(y^i = b, y^{i-1}=a | x) =  \frac{a_a(i-1)P(y^i=b|y^{i-1}=a)P(x^i|y^i=b)\beta_b(i)}{\sum\limits_{a',b'}a_{a'}(i-1)P(y^i=b'|y^{i-1}=a')P(x^i|y^i=b')\beta_{b'}(i)}$$

Here's the code that does exactly that:<br>
<code>
  <pre>
    def unsupervised_learning(self, X, N_iters):
      bar = progressbar.ProgressBar(max_value=N_iters)
      for iter in range(N_iters):
        bar.update(iter)
        temp_A = np.zeros((self.L, self.L))
        temp_O = np.zeros((self.L, self.D))
        A_col = np.zeros(self.L)
        O_col = np.zeros(self.L)
        for x in X:
          M = len(x)
          x_state = np.zeros((M, self.L, self.L))
          alphas = np.array(self.forward(x, normalize=True))
          betas = np.array(self.backward(x, normalize=True))
          c = (alphas * betas)[1:]
          for t in range(len(list(c))):
            b = c[t] / np.sum(c[t])
            O_col += b
            if (M - 1 > t):
              A_col += b
            for i in range(self.L):
              temp_O[i][x[t]] += b[i]
          for t in range(1, M):
            for a in range(self.L):
             for b in range(self.L):
                x_state[t][a][b] += alphas[t][a] * self.A[a][b]
                   * betas[t + 1][b] * self.O[b][x[t]]
          for x_state_i in x_state[1:]:
            temp_A += x_state_i/np.sum(x_state_i) 
        temp_A /= A_col[:,None]
        temp_O /= O_col[:,None]
        self.A = temp_A
        self.O = temp_O
  </pre>
</code>

<h5 style="text-align:center;"><u>Forward-Backward Algorithm</u></h5>

We use the unsupervised learning framework in conjunction with the forward-backward algorithm, instead of the separate forward and backward algorithm that is typically used in conjunction with the Viterbi algorithm. The forward-backward algorithm has 3 key traits:<br><br>

It runs forward: \(\alpha_z(i) = P(x^{1:i},y^i=Z|A,O)\) <br>
It runs backward: \(\beta_z(i) = P(x^{1+i:M}|y^i=Z,A,O)\)<br><br>

For each training \(x = (x^1,...,x^M)\), it computes each \(P(y^i)\) for each \(y = (y^1, ..., y^M)\)
$$ P(y^i=z|x) = \frac{\alpha_z(i)\beta_z(i)}{\sum\limits_{z'}\alpha_{z'}(i)\beta_{z'}(i)}$$

<h5 style="text-align:center;"><u>Generate Emission</u></h5>

We then use these above algorithms to determine the probabilities of forecasted sequences to find the maximum-likelihood sequence:

<code>
  <pre>
    def generate_emission(self, M):
        emission = []
        states = []
        new_state = np.random.choice(self.L, p=self.A_start)
        for i in range(M):
          states.append(new_state)
          emission.append(np.random.choice(self.D, p=self.O[new_state]))
          new_state = np.random.choice(self.L, p=self.A[new_state])
        return emission, state
  </pre>
</code>

<h5 style="text-align:center;"><u>Probabilities - alpha and beta</u></h5>

Similarly, we use the forward and backward (or the forward-backward) algorithm to find the probabilities of the alpha or beta.

<code><pre>
    def probability_alphas(self, x):
        alphas = self.forward(x)
        prob = sum(alphas[-1])
        return prob
</pre></code>

<code><pre>    def probability_betas(self, x):
        betas = self.backward(x)
        prob = sum([betas[1][j] * self.A_start[j] * self.O[j][x[0]] \
                    for j in range(self.L)])
        return prob
</pre></code>

<h5 style="text-align:center;"><u>Generating Sample Sentences</u></h5>

We then trained the HMM on the corpus of the constitution of the United States, and generated some sample sentences.<br>


<h5 style="text-align:center"> Sample Sentence 1</h5> <code>

  Hundred and not its public states shall statebetween number of thing but approved their common prescribe consequence iv he shall regulate the conventions and no...
</code><br>


<h5 style="text-align:center"> Sample Sentence 2</h5> <code>
A they state of no have but thereof declare of in of such be laws shall a to day entitled proceedings of enumeration any privileged...
  </code><br><br>

<h5 style="text-align:center"> Sample Sentence 3</h5> <code>
From foreign of all two to prescribed as whereof laws and to not first states objections elected publish south state and senator prince all no...
  </code><br><br>

<h5 style="text-align:center"> Sample Sentence 4</h5> <code>
  Electors shall jersey taken have thousand on whose and the officer constitute to be weights the privilege a for of the the bill adhering subject...
  </code><br><br>

<h5 style="text-align:center"> Sample Sentence 5</h5> <code>
  From be shall given under if shall reserving the united may public and on both protect to any united of the constitution shall as of...
  </code><br>


<br><h5 style="text-align:center;"><u>Comments about the Sparsity of the A and O matrix</u></h5>

Some interesting insights about the transition matrices \(A\) and \(O\) are that they are extremely sparse. This is actually an expected result, since the HMM enforces a strong regularization through the Baum-Welch (and, even Viterbi) algorithms. The sparsity of these matrices confirms that these algorithms are not overfitting on the dataset particularly, and are thus still capable of generating unique samples from the distribution.

<img src="ProjectPictures/sparsityA.png" style="width:100%;"></p>


<img src="ProjectPictures/sparsityO.png" style="width:100%;"></p>

<br><h5 style="text-align:center;"><u>Visualizations: The Data Wordcloud and How the HMM Transitions between Genres</u></h5>
Here is a word-cloud that we generated of the dataset (the corpus of the United States constitution).
<img src="ProjectPictures/datawordcloud.png" style="width:100%;"></p>

We then generated a word-cloud of the genres of the dataset and categories of words, allowing the HMM to discover 10 hidden states from the corpus.<br>


<img src="ProjectPictures/statewordcloud.png" style="width:100%;"></p>

Finally, we mapped the process of how the HMM transitioned between categories of words when it began the process of generating unique phrases.
<video width="100%" controls>
  <source src="ProjectPictures/datacloud.mov"type="video/mp4">
  <source src="ProjectPictures/datacloud.mov" type="video/ogg">
  Your browser does not support the video tag.
</video>

</div>

<br>

<button class="collapsible centertitleph11"><strong>Leveraging the HMM to Compose Sonnets</strong></button>
  <div class="content"><br>

We then applied the Hidden Markov Model to a new dataset - a corpus of everything Shakespeare ever wrote. We applied it in conjunction with the CMU pronouncing dictionary to determine the stresses of each word to apply further constraints (a 10-syllable count per phrase, a stress-unstress pattern, and an iambic pentameter). We then used an RNN (recurrent neural network) to build a LSTM (long short-term memory) to check that collections of words that were moderately longer made sense (within sufficiently large windows).
</div>

<br>

<button class="collapsible centertitleph11"><strong>Final Report: Hidden Markov Model</strong></button>
  <div class="content">
<p align="center"><iframe src="https://drive.google.com/file/d/1t-JoaiH_HJ2mWBzK2ENCQW6MiMpIIE2d/preview" width="90%" height="720" allow="autoplay"></iframe>


</div>
<br>

<button class="collapsible centertitleph11"><strong>Final Report: Generating Shakespearean Sonnets</strong></button>
  <div class="content">
<p align="center"><iframe src="https://drive.google.com/file/d/1tlKr3FExPrqcOFQyUPTAzUgiPmn7OWPg/preview" width="90%" height="720" allow="autoplay"></iframe>


</div>
<br>

<button class="collapsible centertitleph11"><strong>Code: Hidden Markov Model</strong></button>
  <div class="content">
<p align="center"><script src="https://gist.github.com/emiletimothy/952384fadc93b772e1ed5067ece2ca9d.js"></script></p>
</div>
<br>
<button class="collapsible centertitleph11"><strong>Code: Generating Shakespearean Sonnets</strong></button>
  <div class="content">
<p align="center"><script src="https://gist.github.com/emiletimothy/feb70d2017efb6522134ed3185c20b52.js"></script></p>
</div>


      </div>
    </div>
  </div>
</div>

<style>
.rectangle {
  height: 8%;
  width: 55%;
  background-color: black;
  margin-left: auto;
  margin-right: auto;
  color: white;
  display: flex;
  justify-content:center;
  align-items: center;
}

    .centertitleph112 {
      display: block;
      margin-left: auto;
      margin-right: auto;
      text-align: center;
    }

</style>
</head>

<div class="footer">
    <a href="#" class="w3-button w3-white w3-padding-large w3-margin-bottom"><img src="../up_arrow.png", style="width: 25px;height:25px";></i>To the top</a><br>
    <a href=https://www.instagram.com/emiletimothy/><img src="Pictures/icons/instagram-icon.png", alt="Instagram", style="width:25px;height:25px";></a>
    <a href=https://www.linkedin.com/in/emiletimothy/><img src="Pictures/icons/linkedin-icon.png", alt="Linkedin", style="width:25px;height:25px";></a>
    <a href=https://orcid.org/my-orcid?orcid=0000-0003-2893-9469https://orcid.org/my-orcid?orcid=0000-0003-2893-9469/><img src="Pictures/icons/orcid-icon.png", alt="Orcid", style="width:25px;height:25px";></a>
    <a href=https://scholar.google.com/citations?user=nUXwVU8AAAAJ&hl=en/><img src="Pictures/icons/googlescholar-icon.png", alt="Google Scholar", style="width:25px;height:25px";></a>
    <a href=https://github.com/emiletimothy/><img src="../Pictures/icons/github-icon.png", alt="Github Icon", style="width:30px;height:29px";></a><br><br>
<p1 style="color: white"><br><strong>© 2023 by Emile Timothy</strong></p1>
</div>


</body>

</html>

<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("b1-active");
    var content = this.nextElementSibling;
    if (content.style.maxHeight){
      content.style.maxHeight = null;
    } else {
      content.style.maxHeight = content.scrollHeight + "px";
    }
  });
}
</script>